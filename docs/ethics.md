# Ethical Considerations
While our model provides a useful function of answering questions submitted by the user on youtube videos, there are ethical concerns we must take into account as a result of the inherent problems with both the model itself as well as the data. The first issue arises from the automatic transcription process that we receive from youtube. Since the process of annotating videos is automatic, there will likely be inaccuracies either from a missing or ‘misheard’ word. This could lead to incorrect information provided by the model during use or a lack of understanding on the topic from the model.

Another potential issue comes from the way most LLMs generate answers, especially when prompts are vague or the information is not contained within the dataset. These LLM hallucinations can provide incorrect information to the user while presenting them as facts. Also, being aware of the bias and misinformation from both the model and data is important as well. The dataset used may not reflect all views on certain subjects, resulting in a model that struggles to provide clear and factual information.  

To mitigate some of these issues, we can either create tools or structure the model to provide the most accurate information. For the automatic transcription issues, the creation of our own, more accurate, automatic transcription tool or a data preprocessing tool would be appropriate. To mitigate hallucinations and bias, the model could be given an option to output ‘unknown’ if the level of confidence on an answer is below a certain threshold or be required to provide a timestamp to the section of the video that answers the question. Although these may alleviate some of the ethical concerns, they can never truly be resolved. It is the responsibility of both the user and model creator to understand the risks and shortcomings of the use of LLMs in this context.
